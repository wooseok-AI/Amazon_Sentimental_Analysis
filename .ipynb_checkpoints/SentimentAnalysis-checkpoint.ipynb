{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arm45\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re \n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# 평가함수\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13414, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].nunique(), train['senti'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>senti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J brand is by far the best premium denim line ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I loved this dress. i kept putting it on tryin...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I found this at my local store and ended up bu...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This picture does not due this sweater justice...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am 5' 4\", a size 8-10 (size 29/30), and my f...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13413</th>\n",
       "      <td>These fit quite well, and it's rare that i fin...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13414</th>\n",
       "      <td>I picked this up unexpectedly and whisked it i...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13415</th>\n",
       "      <td>This reminds me of the 1970's. the fabric is s...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13416</th>\n",
       "      <td>Although i love the soft feel of the sweater, ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13417</th>\n",
       "      <td>Not what i was expecting, but pleasantly surpr...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13414 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text senti\n",
       "0      J brand is by far the best premium denim line ...   pos\n",
       "1      I loved this dress. i kept putting it on tryin...   pos\n",
       "2      I found this at my local store and ended up bu...   pos\n",
       "3      This picture does not due this sweater justice...   pos\n",
       "4      I am 5' 4\", a size 8-10 (size 29/30), and my f...   pos\n",
       "...                                                  ...   ...\n",
       "13413  These fit quite well, and it's rare that i fin...   pos\n",
       "13414  I picked this up unexpectedly and whisked it i...   pos\n",
       "13415  This reminds me of the 1970's. the fabric is s...   pos\n",
       "13416  Although i love the soft feel of the sweater, ...   neg\n",
       "13417  Not what i was expecting, but pleasantly surpr...   pos\n",
       "\n",
       "[13414 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop_duplicates(subset=['text'], inplace = True)\n",
    "train.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bb874da3c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['senti'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(word):\n",
    "    result = []\n",
    "    for i in range(len(word)):\n",
    "        w = word[i]\n",
    "        row = []\n",
    "        for v in w.split(\" \"):\n",
    "            r = re.sub('[^a-zA-Z]','', v) \n",
    "            if r != '':\n",
    "                row.append(r)\n",
    "        result.append(\" \".join(row))\n",
    "    return result\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>senti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J brand is by far the best premium denim line ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I loved this dress i kept putting it on trying...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I found this at my local store and ended up bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This picture does not due this sweater justice...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am a size size and my figure is appleish i c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13409</th>\n",
       "      <td>These fit quite well and its rare that i find ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13410</th>\n",
       "      <td>I picked this up unexpectedly and whisked it i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13411</th>\n",
       "      <td>This reminds me of the s the fabric is soft an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13412</th>\n",
       "      <td>Although i love the soft feel of the sweater t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13413</th>\n",
       "      <td>Not what i was expecting but pleasantly surpri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13414 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_cleaned  senti\n",
       "0      J brand is by far the best premium denim line ...      1\n",
       "1      I loved this dress i kept putting it on trying...      1\n",
       "2      I found this at my local store and ended up bu...      1\n",
       "3      This picture does not due this sweater justice...      1\n",
       "4      I am a size size and my figure is appleish i c...      1\n",
       "...                                                  ...    ...\n",
       "13409  These fit quite well and its rare that i find ...      1\n",
       "13410  I picked this up unexpectedly and whisked it i...      1\n",
       "13411  This reminds me of the s the fabric is soft an...      1\n",
       "13412  Although i love the soft feel of the sweater t...      0\n",
       "13413  Not what i was expecting but pleasantly surpri...      1\n",
       "\n",
       "[13414 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = train['text'].to_numpy()\n",
    "\n",
    "result = cleaning(word)\n",
    "cleaned = pd.DataFrame(result,columns = ['text_cleaned'])\n",
    "\n",
    "y_train = train['senti']\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train_encoded = encoder.transform(y_train)\n",
    "\n",
    "senti = pd.DataFrame(y_train_encoded, columns = ['senti'])\n",
    "\n",
    "train_cleaned = pd.concat([cleaned, senti], axis = 1)\n",
    "train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_cleaned    0\n",
       "senti           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>senti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Have to disagree with previous posters i found...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love everything about this top first its sup...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This dress has a marilyn feel to it felt like ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These cords are great the fit the style everyt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This top fit perfectly but too much of my bra ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>Im not the type of woman that wears dresses bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>Super soft and cute the buttons add a nice tou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>These joggers are super cute and comfortable i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>Pilcro denim with embellishment like this alwa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>The fabric of this dress is warm soft and comf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1491 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_cleaned  senti\n",
       "0     Have to disagree with previous posters i found...      1\n",
       "1     I love everything about this top first its sup...      1\n",
       "2     This dress has a marilyn feel to it felt like ...      1\n",
       "3     These cords are great the fit the style everyt...      1\n",
       "4     This top fit perfectly but too much of my bra ...      0\n",
       "...                                                 ...    ...\n",
       "1486  Im not the type of woman that wears dresses bu...      1\n",
       "1487  Super soft and cute the buttons add a nice tou...      1\n",
       "1488  These joggers are super cute and comfortable i...      1\n",
       "1489  Pilcro denim with embellishment like this alwa...      1\n",
       "1490  The fabric of this dress is warm soft and comf...      1\n",
       "\n",
       "[1491 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_test = test['text'].to_numpy()\n",
    "result = cleaning(word_test)\n",
    "cleaned = pd.DataFrame(result,columns = ['text_cleaned'])\n",
    "\n",
    "y_test = test['senti']\n",
    "# pos = 1 neg = 0\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(y_test)\n",
    "y_test_encoded = encoder.transform(y_test)\n",
    "senti = pd.DataFrame(y_test_encoded, columns = ['senti'])\n",
    "\n",
    "test_cleaned = pd.concat([cleaned, senti], axis = 1)\n",
    "test_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned.to_csv('train_cleaned.csv')\n",
    "test_cleaned.to_csv('test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned['token'] = train_cleaned['text_cleaned'].apply(lambda x: x.split(' '))\n",
    "token = train_cleaned['token'].to_numpy()\n",
    "\n",
    "token_train = []\n",
    "for t in token:\n",
    "    cleaned = [w for w in t if w not in stopwords]\n",
    "    token_train.append(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cleaned['token'] = test_cleaned['text_cleaned'].apply(lambda x: x.split(' '))\n",
    "token = test_cleaned['token'].to_numpy()\n",
    "\n",
    "token_test = []\n",
    "for t in token:\n",
    "    cleaned = [w for w in t if w not in stopwords]\n",
    "    token_test.append(cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(token_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of vocab : 14738\n",
      "rare vocabs(under 3) number 10456:\n",
      "percentage of rarevocab: 70.9458542543086\n",
      "perecentage of rarevocab frequency: 3.547320852162686\n"
     ]
    }
   ],
   "source": [
    "threshold = 4 #threshold가 3일때 2보다성능이 낫다\n",
    "total_cnt = len(tokenizer.word_index) \n",
    "rare_cnt = 0 \n",
    "total_freq = 0 \n",
    "rare_freq = 0 \n",
    "\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    \n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "        \n",
    "print('number of vocab :',total_cnt)\n",
    "print('rare vocabs(under %s) number %s:'%(threshold - 1, rare_cnt))\n",
    "print(\"percentage of rarevocab:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"perecentage of rarevocab frequency:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 4283\n"
     ]
    }
   ],
   "source": [
    "vocab_size = total_cnt - rare_cnt + 1 # 빈도수 2이하인 단어 개수는 제거. 0번 패딩 토큰을 고려하여 +1\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_size 이상의 단어들은 제외해버림\n",
    "tokenizer = Tokenizer(vocab_size) \n",
    "tokenizer.fit_on_texts(token_train)\n",
    "X_train = tokenizer.texts_to_sequences(token_train)\n",
    "X_test = tokenizer.texts_to_sequences(token_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, ..., 1, 0, 1]), array([1, 1, 1, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = train_cleaned['senti'].to_numpy()\n",
    "y_test = test_cleaned['senti'].to_numpy()\n",
    "\n",
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 59\n",
      "리뷰의 평균 길이 : 27.845012673326377\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('리뷰의 최대 길이 :',max(len(l) for l in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train_pad = pad_sequences(X_train)\n",
    "X_test_pad = pad_sequences(X_test, maxlen = 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13414"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DL_evaluate(test_x,test_y,model):\n",
    "    predictions = model.predict(test_x)\n",
    "    predictions = np.round(predictions)\n",
    "    print(classification_report(test_y, predictions))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1.0, 0: 5.27}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: round(float(majority)/float(count), 2) for cls, count in counter.items()}\n",
    "\n",
    "class_weights = get_class_weights(train_cleaned.senti)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10731 samples, validate on 2683 samples\n",
      "Epoch 1/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.4066 - acc: 0.8311 - f1_m: 0.8877 - precision_m: 0.9504 - recall_m: 0.8447\n",
      "Epoch 00001: val_acc improved from -inf to 0.92471, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 5s 442us/sample - loss: 0.4041 - acc: 0.8325 - f1_m: 0.8887 - precision_m: 0.9509 - recall_m: 0.8460 - val_loss: 0.2575 - val_acc: 0.9247 - val_f1_m: 0.9531 - val_precision_m: 0.9714 - val_recall_m: 0.9369\n",
      "Epoch 2/15\n",
      "10656/10731 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9469 - f1_m: 0.9670 - precision_m: 0.9886 - recall_m: 0.9477\n",
      "Epoch 00002: val_acc did not improve from 0.92471\n",
      "10731/10731 [==============================] - 4s 350us/sample - loss: 0.1531 - acc: 0.9467 - f1_m: 0.9669 - precision_m: 0.9887 - recall_m: 0.9476 - val_loss: 0.2135 - val_acc: 0.9158 - val_f1_m: 0.9470 - val_precision_m: 0.9837 - val_recall_m: 0.9148\n",
      "Epoch 3/15\n",
      "10592/10731 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9743 - f1_m: 0.9840 - precision_m: 0.9953 - recall_m: 0.9737\n",
      "Epoch 00003: val_acc improved from 0.92471 to 0.93552, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 4s 350us/sample - loss: 0.0843 - acc: 0.9745 - f1_m: 0.9842 - precision_m: 0.9954 - recall_m: 0.9739 - val_loss: 0.2827 - val_acc: 0.9355 - val_f1_m: 0.9606 - val_precision_m: 0.9691 - val_recall_m: 0.9534\n",
      "Epoch 4/15\n",
      "10720/10731 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9848 - f1_m: 0.9906 - precision_m: 0.9976 - recall_m: 0.9841\n",
      "Epoch 00004: val_acc did not improve from 0.93552\n",
      "10731/10731 [==============================] - 4s 348us/sample - loss: 0.0479 - acc: 0.9848 - f1_m: 0.9907 - precision_m: 0.9976 - recall_m: 0.9842 - val_loss: 0.3987 - val_acc: 0.9337 - val_f1_m: 0.9596 - val_precision_m: 0.9638 - val_recall_m: 0.9568\n",
      "Epoch 5/15\n",
      "10592/10731 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9905 - f1_m: 0.9941 - precision_m: 0.9988 - recall_m: 0.9897\n",
      "Epoch 00005: val_acc did not improve from 0.93552\n",
      "10731/10731 [==============================] - 4s 347us/sample - loss: 0.0311 - acc: 0.9904 - f1_m: 0.9941 - precision_m: 0.9989 - recall_m: 0.9896 - val_loss: 0.3545 - val_acc: 0.9210 - val_f1_m: 0.9508 - val_precision_m: 0.9726 - val_recall_m: 0.9317\n",
      "Epoch 6/15\n",
      "10592/10731 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9949 - f1_m: 0.9969 - precision_m: 0.9997 - recall_m: 0.9943\n",
      "Epoch 00006: val_acc did not improve from 0.93552\n",
      "10731/10731 [==============================] - 4s 348us/sample - loss: 0.0163 - acc: 0.9947 - f1_m: 0.9968 - precision_m: 0.9997 - recall_m: 0.9940 - val_loss: 0.4034 - val_acc: 0.9214 - val_f1_m: 0.9518 - val_precision_m: 0.9631 - val_recall_m: 0.9425\n",
      "Epoch 00006: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76       231\n",
      "           1       0.96      0.94      0.95      1260\n",
      "\n",
      "    accuracy                           0.92      1491\n",
      "   macro avg       0.84      0.88      0.85      1491\n",
      "weighted avg       0.93      0.92      0.92      1491\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32)) \n",
    "model.add(SimpleRNN(32)) \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = model.fit(X_train_pad, y_train, epochs=15, batch_size=32,class_weight = class_weights,callbacks=[es, mc], validation_split=0.2)\n",
    "\n",
    "DL_evaluate(X_test_pad, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM,Bidirectional,Dropout,Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1.0, 0: 5.27}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_class_weights(y):\n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    return  {cls: round(float(majority)/float(count), 2) for cls, count in counter.items()}\n",
    "\n",
    "class_weights = get_class_weights(train_cleaned.senti)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1_m' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-548a94a6adab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf1_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprecision_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_m\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m history = model.fit(X_train_pad, y_train, epochs=15, \n\u001b[0;32m     12\u001b[0m                     \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f1_m' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = model.fit(X_train_pad, y_train, epochs=15, \n",
    "                    class_weight = class_weights,callbacks=[es, mc],\n",
    "                    batch_size=60, validation_split=0.2)\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "loss, accuracy, f1_score, precision, recall\n",
    "\n",
    "DL_evaluate(X_test_pad, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10731 samples, validate on 2683 samples\n",
      "Epoch 1/15\n",
      "10680/10731 [============================>.] - ETA: 0s - loss: 0.3902 - acc: 0.8841 - f1_m: 0.9281 - precision_m: 0.9507 - recall_m: 0.9141\n",
      "Epoch 00001: val_acc improved from -inf to 0.91390, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 39s 4ms/sample - loss: 0.3890 - acc: 0.8844 - f1_m: 0.9284 - precision_m: 0.9507 - recall_m: 0.9145 - val_loss: 0.2304 - val_acc: 0.9139 - val_f1_m: 0.9464 - val_precision_m: 0.9826 - val_recall_m: 0.9135\n",
      "Epoch 2/15\n",
      "10680/10731 [============================>.] - ETA: 0s - loss: 0.1814 - acc: 0.9405 - f1_m: 0.9634 - precision_m: 0.9865 - recall_m: 0.9425\n",
      "Epoch 00002: val_acc improved from 0.91390 to 0.94372, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 38s 4ms/sample - loss: 0.1810 - acc: 0.9408 - f1_m: 0.9636 - precision_m: 0.9866 - recall_m: 0.9428 - val_loss: 0.2030 - val_acc: 0.9437 - val_f1_m: 0.9655 - val_precision_m: 0.9790 - val_recall_m: 0.9528\n",
      "Epoch 3/15\n",
      "10680/10731 [============================>.] - ETA: 0s - loss: 0.1458 - acc: 0.9528 - f1_m: 0.9708 - precision_m: 0.9895 - recall_m: 0.9542\n",
      "Epoch 00003: val_acc improved from 0.94372 to 0.94707, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 38s 4ms/sample - loss: 0.1458 - acc: 0.9529 - f1_m: 0.9709 - precision_m: 0.9894 - recall_m: 0.9544 - val_loss: 0.2319 - val_acc: 0.9471 - val_f1_m: 0.9684 - val_precision_m: 0.9726 - val_recall_m: 0.9647\n",
      "Epoch 4/15\n",
      "10680/10731 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9603 - f1_m: 0.9756 - precision_m: 0.9911 - recall_m: 0.9613\n",
      "Epoch 00004: val_acc did not improve from 0.94707\n",
      "10731/10731 [==============================] - 37s 3ms/sample - loss: 0.1246 - acc: 0.9605 - f1_m: 0.9757 - precision_m: 0.9912 - recall_m: 0.9616 - val_loss: 0.2268 - val_acc: 0.9422 - val_f1_m: 0.9652 - val_precision_m: 0.9702 - val_recall_m: 0.9611\n",
      "Epoch 5/15\n",
      "10680/10731 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9645 - f1_m: 0.9782 - precision_m: 0.9928 - recall_m: 0.9648\n",
      "Epoch 00005: val_acc did not improve from 0.94707\n",
      "10731/10731 [==============================] - 37s 3ms/sample - loss: 0.1097 - acc: 0.9644 - f1_m: 0.9781 - precision_m: 0.9927 - recall_m: 0.9647 - val_loss: 0.1859 - val_acc: 0.9337 - val_f1_m: 0.9593 - val_precision_m: 0.9868 - val_recall_m: 0.9339\n",
      "Epoch 6/15\n",
      "10680/10731 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9658 - f1_m: 0.9789 - precision_m: 0.9937 - recall_m: 0.9655\n",
      "Epoch 00006: val_acc did not improve from 0.94707\n",
      "10731/10731 [==============================] - 38s 4ms/sample - loss: 0.1026 - acc: 0.9657 - f1_m: 0.9788 - precision_m: 0.9937 - recall_m: 0.9653 - val_loss: 0.1863 - val_acc: 0.9355 - val_f1_m: 0.9602 - val_precision_m: 0.9819 - val_recall_m: 0.9404\n",
      "Epoch 7/15\n",
      "10680/10731 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9681 - f1_m: 0.9803 - precision_m: 0.9940 - recall_m: 0.9679\n",
      "Epoch 00007: val_acc improved from 0.94707 to 0.94931, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 38s 4ms/sample - loss: 0.0898 - acc: 0.9680 - f1_m: 0.9803 - precision_m: 0.9940 - recall_m: 0.9678 - val_loss: 0.2913 - val_acc: 0.9493 - val_f1_m: 0.9693 - val_precision_m: 0.9742 - val_recall_m: 0.9650\n",
      "Epoch 8/15\n",
      "10680/10731 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9718 - f1_m: 0.9828 - precision_m: 0.9946 - recall_m: 0.9718\n",
      "Epoch 00008: val_acc did not improve from 0.94931\n",
      "10731/10731 [==============================] - 37s 3ms/sample - loss: 0.0808 - acc: 0.9720 - f1_m: 0.9829 - precision_m: 0.9947 - recall_m: 0.9720 - val_loss: 0.4102 - val_acc: 0.9471 - val_f1_m: 0.9686 - val_precision_m: 0.9568 - val_recall_m: 0.9810\n",
      "Epoch 9/15\n",
      "10680/10731 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9746 - f1_m: 0.9843 - precision_m: 0.9954 - recall_m: 0.9742\n",
      "Epoch 00009: val_acc improved from 0.94931 to 0.95080, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 38s 4ms/sample - loss: 0.0737 - acc: 0.9747 - f1_m: 0.9844 - precision_m: 0.9955 - recall_m: 0.9743 - val_loss: 0.2910 - val_acc: 0.9508 - val_f1_m: 0.9705 - val_precision_m: 0.9685 - val_recall_m: 0.9733\n",
      "Epoch 00009: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83       231\n",
      "           1       0.97      0.97      0.97      1260\n",
      "\n",
      "    accuracy                           0.95      1491\n",
      "   macro avg       0.90      0.90      0.90      1491\n",
      "weighted avg       0.95      0.95      0.95      1491\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = model.fit(X_train_pad, y_train, epochs=15, \n",
    "                    class_weight = class_weights,callbacks=[es, mc], \n",
    "                    batch_size=60, validation_split=0.2)\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "loss, accuracy, f1_score, precision, recall\n",
    "\n",
    "DL_evaluate(X_test_pad, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10731 samples, validate on 2683 samples\n",
      "Epoch 1/15\n",
      "10731/10731 [==============================] - 13s 1ms/sample - loss: 0.4464 - acc: 0.7955 - f1_m: 0.8500 - precision_m: 0.9413 - recall_m: 0.8045 - val_loss: 0.2411 - val_acc: 0.9150 - val_f1_m: 0.9473 - val_precision_m: 0.9781 - val_recall_m: 0.9194\n",
      "Epoch 2/15\n",
      "10731/10731 [==============================] - 13s 1ms/sample - loss: 0.1987 - acc: 0.9331 - f1_m: 0.9586 - precision_m: 0.9853 - recall_m: 0.9349 - val_loss: 0.2170 - val_acc: 0.9143 - val_f1_m: 0.9464 - val_precision_m: 0.9840 - val_recall_m: 0.9126\n",
      "Epoch 3/15\n",
      "10731/10731 [==============================] - 12s 1ms/sample - loss: 0.1410 - acc: 0.9492 - f1_m: 0.9685 - precision_m: 0.9900 - recall_m: 0.9491 - val_loss: 0.2353 - val_acc: 0.9199 - val_f1_m: 0.9505 - val_precision_m: 0.9801 - val_recall_m: 0.9231\n",
      "Epoch 4/15\n",
      "10731/10731 [==============================] - 12s 1ms/sample - loss: 0.1114 - acc: 0.9624 - f1_m: 0.9770 - precision_m: 0.9937 - recall_m: 0.9617 - val_loss: 0.2967 - val_acc: 0.9385 - val_f1_m: 0.9631 - val_precision_m: 0.9672 - val_recall_m: 0.9599\n",
      "Epoch 5/15\n",
      "10731/10731 [==============================] - 11s 1ms/sample - loss: 0.0861 - acc: 0.9741 - f1_m: 0.9841 - precision_m: 0.9956 - recall_m: 0.9735 - val_loss: 0.5021 - val_acc: 0.9392 - val_f1_m: 0.9640 - val_precision_m: 0.9500 - val_recall_m: 0.9792\n",
      "Epoch 6/15\n",
      "10731/10731 [==============================] - 11s 1ms/sample - loss: 0.0663 - acc: 0.9782 - f1_m: 0.9867 - precision_m: 0.9957 - recall_m: 0.9786 - val_loss: 0.4055 - val_acc: 0.9404 - val_f1_m: 0.9639 - val_precision_m: 0.9695 - val_recall_m: 0.9591loss: 0.0655 - acc: 0.9789 - f1_m: 0.9872 - p\n",
      "Epoch 7/15\n",
      "10731/10731 [==============================] - 11s 1ms/sample - loss: 0.0500 - acc: 0.9847 - f1_m: 0.9908 - precision_m: 0.9969 - recall_m: 0.9853 - val_loss: 0.3802 - val_acc: 0.9329 - val_f1_m: 0.9592 - val_precision_m: 0.9751 - val_recall_m: 0.9446\n",
      "Epoch 8/15\n",
      "10731/10731 [==============================] - 11s 1ms/sample - loss: 0.0422 - acc: 0.9891 - f1_m: 0.9934 - precision_m: 0.9981 - recall_m: 0.9890 - val_loss: 0.4962 - val_acc: 0.9378 - val_f1_m: 0.9623 - val_precision_m: 0.9712 - val_recall_m: 0.9544\n",
      "Epoch 9/15\n",
      "10731/10731 [==============================] - 11s 1ms/sample - loss: 0.0346 - acc: 0.9900 - f1_m: 0.9940 - precision_m: 0.9982 - recall_m: 0.9901 - val_loss: 0.6535 - val_acc: 0.9359 - val_f1_m: 0.9618 - val_precision_m: 0.9573 - val_recall_m: 0.9671\n",
      "Epoch 10/15\n",
      "10731/10731 [==============================] - 11s 1ms/sample - loss: 0.0271 - acc: 0.9924 - f1_m: 0.9954 - precision_m: 0.9985 - recall_m: 0.9926 - val_loss: 0.6737 - val_acc: 0.9374 - val_f1_m: 0.9625 - val_precision_m: 0.9588 - val_recall_m: 0.9671\n",
      "Epoch 11/15\n",
      "10731/10731 [==============================] - 12s 1ms/sample - loss: 0.0206 - acc: 0.9951 - f1_m: 0.9969 - precision_m: 0.9990 - recall_m: 0.9951 - val_loss: 0.6906 - val_acc: 0.9307 - val_f1_m: 0.9578 - val_precision_m: 0.9715 - val_recall_m: 0.9450\n",
      "Epoch 12/15\n",
      "10731/10731 [==============================] - 11s 1ms/sample - loss: 0.0184 - acc: 0.9966 - f1_m: 0.9980 - precision_m: 0.9991 - recall_m: 0.9969 - val_loss: 1.2544 - val_acc: 0.9322 - val_f1_m: 0.9595 - val_precision_m: 0.9437 - val_recall_m: 0.9764\n",
      "Epoch 13/15\n",
      "10731/10731 [==============================] - 11s 1ms/sample - loss: 0.0167 - acc: 0.9980 - f1_m: 0.9988 - precision_m: 0.9993 - recall_m: 0.9984 - val_loss: 1.1841 - val_acc: 0.9396 - val_f1_m: 0.9639 - val_precision_m: 0.9625 - val_recall_m: 0.9660\n",
      "Epoch 14/15\n",
      "10731/10731 [==============================] - 11s 1ms/sample - loss: 0.0071 - acc: 0.9988 - f1_m: 0.9993 - precision_m: 0.9995 - recall_m: 0.9990 - val_loss: 1.1414 - val_acc: 0.9351 - val_f1_m: 0.9611 - val_precision_m: 0.9618 - val_recall_m: 0.9610\n",
      "Epoch 15/15\n",
      "10731/10731 [==============================] - 14s 1ms/sample - loss: 0.0143 - acc: 0.9979 - f1_m: 0.9988 - precision_m: 0.9992 - recall_m: 0.9984 - val_loss: 1.2406 - val_acc: 0.9333 - val_f1_m: 0.9602 - val_precision_m: 0.9568 - val_recall_m: 0.9644\n",
      "0.615732964166046 0.9356137 0.9615189 0.9557971 0.96845716\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78       231\n",
      "           1       0.96      0.97      0.96      1260\n",
      "\n",
      "    accuracy                           0.94      1491\n",
      "   macro avg       0.89      0.86      0.87      1491\n",
      "weighted avg       0.93      0.94      0.93      1491\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best 2\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128, input_length=59))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(256,3,padding='valid',activation='relu',strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = model.fit(X_train_pad, y_train, class_weight = class_weights,epochs=15, batch_size=60, validation_split=0.2)\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(X_test_pad, y_test, verbose=0)\n",
    "\n",
    "print(loss, accuracy, f1_score, precision, recall)\n",
    "\n",
    "# Plotting the history\n",
    "%matplotlib inline\n",
    "\n",
    "history_dict = history.history\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validatin loss')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# evaluation\n",
    "DL_evaluate(X_test_pad, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model Hype Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional,Dropout\n",
    "from tensorflow.keras.layers import Flatten, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10731 samples, validate on 2683 samples\n",
      "Epoch 1/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.3738 - acc: 0.8573 - f1_m: 0.9075 - precision_m: 0.9646 - recall_m: 0.8644\n",
      "Epoch 00001: val_acc improved from -inf to 0.93589, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 61s 6ms/sample - loss: 0.3719 - acc: 0.8583 - f1_m: 0.9083 - precision_m: 0.9651 - recall_m: 0.8653 - val_loss: 0.2434 - val_acc: 0.9359 - val_f1_m: 0.9611 - val_precision_m: 0.9716 - val_recall_m: 0.9510\n",
      "Epoch 2/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9392 - f1_m: 0.9627 - precision_m: 0.9865 - recall_m: 0.9408\n",
      "Epoch 00002: val_acc improved from 0.93589 to 0.94447, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 58s 5ms/sample - loss: 0.1769 - acc: 0.9391 - f1_m: 0.9626 - precision_m: 0.9865 - recall_m: 0.9405 - val_loss: 0.2113 - val_acc: 0.9445 - val_f1_m: 0.9665 - val_precision_m: 0.9774 - val_recall_m: 0.9561\n",
      "Epoch 3/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.1268 - acc: 0.9565 - f1_m: 0.9735 - precision_m: 0.9918 - recall_m: 0.9563\n",
      "Epoch 00003: val_acc did not improve from 0.94447\n",
      "10731/10731 [==============================] - 59s 6ms/sample - loss: 0.1278 - acc: 0.9566 - f1_m: 0.9735 - precision_m: 0.9918 - recall_m: 0.9564 - val_loss: 0.1984 - val_acc: 0.9273 - val_f1_m: 0.9553 - val_precision_m: 0.9834 - val_recall_m: 0.9292\n",
      "Epoch 4/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9675 - f1_m: 0.9802 - precision_m: 0.9938 - recall_m: 0.9673\n",
      "Epoch 00004: val_acc improved from 0.94447 to 0.94931, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 61s 6ms/sample - loss: 0.1044 - acc: 0.9675 - f1_m: 0.9801 - precision_m: 0.9939 - recall_m: 0.9672 - val_loss: 0.2403 - val_acc: 0.9493 - val_f1_m: 0.9696 - val_precision_m: 0.9740 - val_recall_m: 0.9654\n",
      "Epoch 5/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9712 - f1_m: 0.9818 - precision_m: 0.9956 - recall_m: 0.9704\n",
      "Epoch 00005: val_acc did not improve from 0.94931\n",
      "10731/10731 [==============================] - 60s 6ms/sample - loss: 0.0900 - acc: 0.9711 - f1_m: 0.9817 - precision_m: 0.9955 - recall_m: 0.9703 - val_loss: 0.2079 - val_acc: 0.9288 - val_f1_m: 0.9563 - val_precision_m: 0.9819 - val_recall_m: 0.9325\n",
      "Epoch 6/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9757 - f1_m: 0.9853 - precision_m: 0.9955 - recall_m: 0.9757\n",
      "Epoch 00006: val_acc did not improve from 0.94931\n",
      "10731/10731 [==============================] - 67s 6ms/sample - loss: 0.0688 - acc: 0.9757 - f1_m: 0.9853 - precision_m: 0.9955 - recall_m: 0.9756 - val_loss: 0.2605 - val_acc: 0.9426 - val_f1_m: 0.9657 - val_precision_m: 0.9684 - val_recall_m: 0.9632\n",
      "Epoch 7/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9808 - f1_m: 0.9881 - precision_m: 0.9967 - recall_m: 0.9802\n",
      "Epoch 00007: val_acc did not improve from 0.94931\n",
      "10731/10731 [==============================] - 65s 6ms/sample - loss: 0.0577 - acc: 0.9807 - f1_m: 0.9880 - precision_m: 0.9966 - recall_m: 0.9802 - val_loss: 0.2911 - val_acc: 0.9437 - val_f1_m: 0.9662 - val_precision_m: 0.9699 - val_recall_m: 0.9628\n",
      "Epoch 00007: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82       231\n",
      "           1       0.97      0.96      0.97      1260\n",
      "\n",
      "    accuracy                           0.94      1491\n",
      "   macro avg       0.89      0.90      0.89      1491\n",
      "weighted avg       0.95      0.94      0.94      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# best1\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = model.fit(X_train_pad, y_train, epochs=15, class_weight = class_weights,callbacks=[es, mc], batch_size=128, validation_split=0.2)\n",
    "\n",
    "LSTM_best_result = DL_evaluate(X_test_pad, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10731 samples, validate on 2683 samples\n",
      "Epoch 1/15\n",
      "10496/10731 [============================>.] - ETA: 0s - loss: 0.5649 - acc: 0.7470 - f1_m: 0.7888 - precision_m: 0.8759 - recall_m: 0.7504\n",
      "Epoch 00001: val_acc improved from -inf to 0.84830, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 24s 2ms/sample - loss: 0.5590 - acc: 0.7508 - f1_m: 0.7927 - precision_m: 0.8787 - recall_m: 0.7543 - val_loss: 0.3270 - val_acc: 0.8483 - val_f1_m: 0.9025 - val_precision_m: 0.9768 - val_recall_m: 0.8388\n",
      "Epoch 2/15\n",
      "10496/10731 [============================>.] - ETA: 0s - loss: 0.2578 - acc: 0.9098 - f1_m: 0.9433 - precision_m: 0.9821 - recall_m: 0.9097\n",
      "Epoch 00002: val_acc improved from 0.84830 to 0.92695, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 21s 2ms/sample - loss: 0.2558 - acc: 0.9105 - f1_m: 0.9438 - precision_m: 0.9823 - recall_m: 0.9106 - val_loss: 0.2465 - val_acc: 0.9269 - val_f1_m: 0.9554 - val_precision_m: 0.9714 - val_recall_m: 0.9400\n",
      "Epoch 3/15\n",
      "10496/10731 [============================>.] - ETA: 0s - loss: 0.1753 - acc: 0.9376 - f1_m: 0.9617 - precision_m: 0.9875 - recall_m: 0.9379\n",
      "Epoch 00003: val_acc improved from 0.92695 to 0.92844, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 22s 2ms/sample - loss: 0.1759 - acc: 0.9374 - f1_m: 0.9616 - precision_m: 0.9874 - recall_m: 0.9377 - val_loss: 0.2129 - val_acc: 0.9284 - val_f1_m: 0.9564 - val_precision_m: 0.9804 - val_recall_m: 0.9338\n",
      "Epoch 4/15\n",
      "10496/10731 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9557 - f1_m: 0.9730 - precision_m: 0.9918 - recall_m: 0.9553\n",
      "Epoch 00004: val_acc improved from 0.92844 to 0.93776, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 22s 2ms/sample - loss: 0.1342 - acc: 0.9556 - f1_m: 0.9730 - precision_m: 0.9916 - recall_m: 0.9554 - val_loss: 0.2385 - val_acc: 0.9378 - val_f1_m: 0.9613 - val_precision_m: 0.9725 - val_recall_m: 0.9507\n",
      "Epoch 5/15\n",
      "10496/10731 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9617 - f1_m: 0.9767 - precision_m: 0.9932 - recall_m: 0.9610\n",
      "Epoch 00005: val_acc improved from 0.93776 to 0.93925, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 23s 2ms/sample - loss: 0.1129 - acc: 0.9620 - f1_m: 0.9769 - precision_m: 0.9933 - recall_m: 0.9613 - val_loss: 0.2612 - val_acc: 0.9392 - val_f1_m: 0.9630 - val_precision_m: 0.9748 - val_recall_m: 0.9515\n",
      "Epoch 6/15\n",
      "10496/10731 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9657 - f1_m: 0.9791 - precision_m: 0.9946 - recall_m: 0.9644\n",
      "Epoch 00006: val_acc did not improve from 0.93925\n",
      "10731/10731 [==============================] - 23s 2ms/sample - loss: 0.0977 - acc: 0.9660 - f1_m: 0.9793 - precision_m: 0.9943 - recall_m: 0.9651 - val_loss: 0.2291 - val_acc: 0.9187 - val_f1_m: 0.9501 - val_precision_m: 0.9776 - val_recall_m: 0.9242\n",
      "Epoch 7/15\n",
      "10496/10731 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9736 - f1_m: 0.9841 - precision_m: 0.9957 - recall_m: 0.9728\n",
      "Epoch 00007: val_acc improved from 0.93925 to 0.94521, saving model to best_model.h5\n",
      "10731/10731 [==============================] - 23s 2ms/sample - loss: 0.0810 - acc: 0.9733 - f1_m: 0.9839 - precision_m: 0.9955 - recall_m: 0.9727 - val_loss: 0.2987 - val_acc: 0.9452 - val_f1_m: 0.9671 - val_precision_m: 0.9688 - val_recall_m: 0.9656\n",
      "Epoch 00007: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83       231\n",
      "           1       0.97      0.97      0.97      1260\n",
      "\n",
      "    accuracy                           0.95      1491\n",
      "   macro avg       0.90      0.90      0.90      1491\n",
      "weighted avg       0.95      0.95      0.95      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# best1\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 59))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = model.fit(X_train_pad, y_train, epochs=15, class_weight = class_weights,callbacks=[es, mc], batch_size=256, validation_split=0.2)\n",
    "\n",
    "LSTM_best_result2 = DL_evaluate(X_test_pad, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10731 samples, validate on 2683 samples\n",
      "Epoch 1/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.4367 - acc: 0.8660 - f1_m: 0.9092 - precision_m: 0.9529 - recall_m: 0.8873\n",
      "Epoch 00001: val_acc did not improve from 0.94819\n",
      "10731/10731 [==============================] - 19s 2ms/sample - loss: 0.4342 - acc: 0.8667 - f1_m: 0.9098 - precision_m: 0.9532 - recall_m: 0.8881 - val_loss: 0.2223 - val_acc: 0.9068 - val_f1_m: 0.9417 - val_precision_m: 0.9849 - val_recall_m: 0.9025\n",
      "Epoch 2/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.1853 - acc: 0.9369 - f1_m: 0.9607 - precision_m: 0.9859 - recall_m: 0.9390\n",
      "Epoch 00002: val_acc did not improve from 0.94819\n",
      "10731/10731 [==============================] - 18s 2ms/sample - loss: 0.1851 - acc: 0.9371 - f1_m: 0.9609 - precision_m: 0.9859 - recall_m: 0.9392 - val_loss: 0.2116 - val_acc: 0.9187 - val_f1_m: 0.9496 - val_precision_m: 0.9832 - val_recall_m: 0.9184\n",
      "Epoch 3/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9518 - f1_m: 0.9704 - precision_m: 0.9907 - recall_m: 0.9518\n",
      "Epoch 00003: val_acc did not improve from 0.94819\n",
      "10731/10731 [==============================] - 18s 2ms/sample - loss: 0.1391 - acc: 0.9522 - f1_m: 0.9707 - precision_m: 0.9909 - recall_m: 0.9523 - val_loss: 0.2575 - val_acc: 0.9441 - val_f1_m: 0.9664 - val_precision_m: 0.9728 - val_recall_m: 0.9604\n",
      "Epoch 4/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9633 - f1_m: 0.9774 - precision_m: 0.9930 - recall_m: 0.9631\n",
      "Epoch 00004: val_acc did not improve from 0.94819\n",
      "10731/10731 [==============================] - 19s 2ms/sample - loss: 0.1104 - acc: 0.9635 - f1_m: 0.9775 - precision_m: 0.9928 - recall_m: 0.9636 - val_loss: 0.2487 - val_acc: 0.8729 - val_f1_m: 0.9186 - val_precision_m: 0.9913 - val_recall_m: 0.8561\n",
      "Epoch 5/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9700 - f1_m: 0.9817 - precision_m: 0.9953 - recall_m: 0.9691\n",
      "Epoch 00005: val_acc did not improve from 0.94819\n",
      "10731/10731 [==============================] - 19s 2ms/sample - loss: 0.0883 - acc: 0.9699 - f1_m: 0.9816 - precision_m: 0.9950 - recall_m: 0.9691 - val_loss: 0.2344 - val_acc: 0.9359 - val_f1_m: 0.9610 - val_precision_m: 0.9781 - val_recall_m: 0.9450\n",
      "Epoch 6/15\n",
      "10624/10731 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9782 - f1_m: 0.9866 - precision_m: 0.9965 - recall_m: 0.9773\n",
      "Epoch 00006: val_acc did not improve from 0.94819\n",
      "10731/10731 [==============================] - 19s 2ms/sample - loss: 0.0679 - acc: 0.9782 - f1_m: 0.9867 - precision_m: 0.9966 - recall_m: 0.9774 - val_loss: 0.2949 - val_acc: 0.9426 - val_f1_m: 0.9655 - val_precision_m: 0.9683 - val_recall_m: 0.9629\n",
      "Epoch 00006: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       231\n",
      "           1       0.97      0.96      0.96      1260\n",
      "\n",
      "    accuracy                           0.94      1491\n",
      "   macro avg       0.88      0.89      0.89      1491\n",
      "weighted avg       0.94      0.94      0.94      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# best1\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = model.fit(X_train_pad, y_train, epochs=15, class_weight = class_weights,callbacks=[es, mc], batch_size=128, validation_split=0.2)\n",
    "\n",
    "LSTM_result3 = DL_evaluate(X_test_pad, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10731 samples, validate on 2683 samples\n",
      "Epoch 1/15\n",
      "10731/10731 [==============================] - 10s 965us/sample - loss: 0.4620 - acc: 0.8041 - f1_m: 0.8650 - precision_m: 0.9387 - recall_m: 0.8214 - val_loss: 0.2543 - val_acc: 0.8807 - val_f1_m: 0.9242 - val_precision_m: 0.9846 - val_recall_m: 0.8716\n",
      "Epoch 2/15\n",
      "10731/10731 [==============================] - 9s 816us/sample - loss: 0.1859 - acc: 0.9381 - f1_m: 0.9618 - precision_m: 0.9864 - recall_m: 0.9396 - val_loss: 0.2160 - val_acc: 0.9273 - val_f1_m: 0.9553 - val_precision_m: 0.9798 - val_recall_m: 0.9323\n",
      "Epoch 3/15\n",
      "10731/10731 [==============================] - 9s 827us/sample - loss: 0.1066 - acc: 0.9668 - f1_m: 0.9798 - precision_m: 0.9937 - recall_m: 0.9669 - val_loss: 0.2818 - val_acc: 0.9400 - val_f1_m: 0.9640 - val_precision_m: 0.9695 - val_recall_m: 0.9588\n",
      "Epoch 4/15\n",
      "10731/10731 [==============================] - 10s 954us/sample - loss: 0.0666 - acc: 0.9815 - f1_m: 0.9888 - precision_m: 0.9962 - recall_m: 0.9817 - val_loss: 0.3051 - val_acc: 0.9415 - val_f1_m: 0.9648 - val_precision_m: 0.9687 - val_recall_m: 0.9612\n",
      "Epoch 5/15\n",
      "10731/10731 [==============================] - 10s 969us/sample - loss: 0.0429 - acc: 0.9899 - f1_m: 0.9939 - precision_m: 0.9975 - recall_m: 0.9905 - val_loss: 0.3172 - val_acc: 0.9415 - val_f1_m: 0.9649 - val_precision_m: 0.9696 - val_recall_m: 0.9607\n",
      "Epoch 6/15\n",
      "10731/10731 [==============================] - 10s 968us/sample - loss: 0.0311 - acc: 0.9924 - f1_m: 0.9953 - precision_m: 0.9981 - recall_m: 0.9927 - val_loss: 0.3807 - val_acc: 0.9422 - val_f1_m: 0.9655 - val_precision_m: 0.9663 - val_recall_m: 0.9649\n",
      "Epoch 7/15\n",
      "10731/10731 [==============================] - 10s 976us/sample - loss: 0.0213 - acc: 0.9949 - f1_m: 0.9969 - precision_m: 0.9989 - recall_m: 0.9950 - val_loss: 0.3438 - val_acc: 0.9292 - val_f1_m: 0.9565 - val_precision_m: 0.9789 - val_recall_m: 0.9355\n",
      "Epoch 8/15\n",
      "10731/10731 [==============================] - 11s 982us/sample - loss: 0.0174 - acc: 0.9958 - f1_m: 0.9974 - precision_m: 0.9992 - recall_m: 0.9957 - val_loss: 0.5146 - val_acc: 0.9437 - val_f1_m: 0.9663 - val_precision_m: 0.9665 - val_recall_m: 0.9662\n",
      "Epoch 9/15\n",
      "10731/10731 [==============================] - 10s 970us/sample - loss: 0.0072 - acc: 0.9978 - f1_m: 0.9987 - precision_m: 0.9996 - recall_m: 0.9978 - val_loss: 0.8261 - val_acc: 0.9411 - val_f1_m: 0.9652 - val_precision_m: 0.9521 - val_recall_m: 0.9791\n",
      "Epoch 10/15\n",
      "10731/10731 [==============================] - 10s 972us/sample - loss: 0.0053 - acc: 0.9986 - f1_m: 0.9992 - precision_m: 0.9997 - recall_m: 0.9987 - val_loss: 0.8190 - val_acc: 0.9415 - val_f1_m: 0.9654 - val_precision_m: 0.9561 - val_recall_m: 0.9753\n",
      "Epoch 11/15\n",
      "10731/10731 [==============================] - 10s 971us/sample - loss: 9.5583e-04 - acc: 0.9997 - f1_m: 0.9998 - precision_m: 0.9999 - recall_m: 0.9998 - val_loss: 1.1063 - val_acc: 0.9392 - val_f1_m: 0.9641 - val_precision_m: 0.9540 - val_recall_m: 0.9747\n",
      "Epoch 12/15\n",
      "10731/10731 [==============================] - 10s 972us/sample - loss: 0.0029 - acc: 0.9993 - f1_m: 0.9996 - precision_m: 0.9998 - recall_m: 0.9994 - val_loss: 1.0217 - val_acc: 0.9392 - val_f1_m: 0.9642 - val_precision_m: 0.9566 - val_recall_m: 0.9722\n",
      "Epoch 13/15\n",
      "10731/10731 [==============================] - 10s 960us/sample - loss: 0.0021 - acc: 0.9996 - f1_m: 0.9998 - precision_m: 0.9998 - recall_m: 0.9998 - val_loss: 1.1877 - val_acc: 0.9389 - val_f1_m: 0.9637 - val_precision_m: 0.9525 - val_recall_m: 0.9754\n",
      "Epoch 14/15\n",
      "10731/10731 [==============================] - 10s 969us/sample - loss: 0.0025 - acc: 0.9993 - f1_m: 0.9996 - precision_m: 0.9999 - recall_m: 0.9994 - val_loss: 1.1618 - val_acc: 0.9407 - val_f1_m: 0.9650 - val_precision_m: 0.9532 - val_recall_m: 0.9774\n",
      "Epoch 15/15\n",
      "10731/10731 [==============================] - 10s 966us/sample - loss: 1.1384e-05 - acc: 1.0000 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.0000 - val_loss: 1.6530 - val_acc: 0.9381 - val_f1_m: 0.9636 - val_precision_m: 0.9485 - val_recall_m: 0.9795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.71      0.80       231\n",
      "           1       0.95      0.99      0.97      1260\n",
      "\n",
      "    accuracy                           0.95      1491\n",
      "   macro avg       0.94      0.85      0.89      1491\n",
      "weighted avg       0.95      0.95      0.94      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# best 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 256, input_length=59))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(128,3,padding='valid',activation='relu',strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "history = model.fit(X_train_pad, y_train, class_weight = class_weights,epochs=15, batch_size=128, validation_split=0.2)\n",
    "\n",
    "# evaluation\n",
    "CNN_result = DL_evaluate(X_test_pad, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/1\", trainable=True)\n",
    "# 텐서플로우 허브로부터 ELMo를 다운로드\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_cleaned.csv',usecols=[1,2])\n",
    "test = pd.read_csv('test_cleaned.csv',usecols=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_duplicates(subset=['text_cleaned'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(train['text_cleaned'])\n",
    "y_train = list(train['senti'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13414, 13414)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELMoEmbedding(x):\n",
    "    return elmo(tf.squeeze(tf.cast(x, tf.string)), as_dict=True, signature=\"default\")[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Lambda, Input\n",
    "\n",
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding_layer = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
    "hidden_layer = Dense(256, activation='relu')(embedding_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer)\n",
    "elmo = Model(inputs=[input_text], outputs=output_layer)\n",
    "elmo.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10731 samples, validate on 2683 samples\n",
      "Epoch 1/5\n",
      "10731/10731 [==============================] - 3814s 355ms/sample - loss: 0.3395 - acc: 0.8639 - val_loss: 0.2430 - val_acc: 0.8938\n",
      "Epoch 2/5\n",
      "10731/10731 [==============================] - 3697s 345ms/sample - loss: 0.2463 - acc: 0.9004 - val_loss: 0.2320 - val_acc: 0.9132\n",
      "Epoch 3/5\n",
      "10731/10731 [==============================] - 3764s 351ms/sample - loss: 0.2193 - acc: 0.9118 - val_loss: 0.2788 - val_acc: 0.8837\n",
      "Epoch 4/5\n",
      "10731/10731 [==============================] - 3690s 344ms/sample - loss: 0.2044 - acc: 0.9148 - val_loss: 0.1907 - val_acc: 0.9322\n",
      "Epoch 5/5\n",
      "10731/10731 [==============================] - 3689s 344ms/sample - loss: 0.1996 - acc: 0.9173 - val_loss: 0.1799 - val_acc: 0.9329\n"
     ]
    }
   ],
   "source": [
    "history = elmo.fit(X_train, y_train, epochs=5, batch_size=256, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = list(test_cleaned['text_cleaned'])\n",
    "y_test = list(test_cleaned['senti'])\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77       231\n",
      "           1       0.96      0.96      0.96      1260\n",
      "\n",
      "    accuracy                           0.93      1491\n",
      "   macro avg       0.87      0.86      0.86      1491\n",
      "weighted avg       0.93      0.93      0.93      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "elmo_result = DL_evaluate(X_test, y_test, elmo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가함수\n",
    "\n",
    "def evaluate(test_x,test_y,model):\n",
    "    predictions = model.predict(test_x)\n",
    "    print(classification_report(test_y, predictions))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = pd.read_csv('train_cleaned.csv',usecols = [1,2])\n",
    "test_cleaned = pd.read_csv('test_cleaned.csv',usecols = [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_cleaned['text_cleaned'].tolist()\n",
    "y_train = train_cleaned['senti'].to_numpy()\n",
    "\n",
    "x_test = test_cleaned['text_cleaned'].tolist()\n",
    "y_test = test_cleaned['senti'].to_numpy()\n",
    "vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                             min_df = 5,\n",
    "                             sublinear_tf = True,\n",
    "                             ngram_range=(1,2))\n",
    "\n",
    "# vectorizer = TfidfVectorizer(stop_words='english', min_df = 4,sublinear_tf = True,ngram_range=(1,2))\n",
    "x_train_vector = vectorizer.fit_transform(x_train)\n",
    "x_test_vector = vectorizer.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_cleaned['text_cleaned'].tolist()\n",
    "y_train = train_cleaned['senti'].to_numpy()\n",
    "\n",
    "x_test = test_cleaned['text_cleaned'].tolist()\n",
    "y_test = test_cleaned['senti'].to_numpy()\n",
    "vectorizer2 = TfidfVectorizer(stop_words='english',\n",
    "                             min_df = 4,\n",
    "                             sublinear_tf = True,\n",
    "                             ngram_range=(1,3))\n",
    "\n",
    "# vectorizer = TfidfVectorizer(stop_words='english', min_df = 4,sublinear_tf = True,ngram_range=(1,2))\n",
    "x_train_vector2 = vectorizer2.fit_transform(x_train)\n",
    "x_test_vector2 = vectorizer2.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.13704397, 3.13704397, 3.13704397, ..., 3.13704397, 0.59480312,\n",
       "       3.13704397])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = list(class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(y_train),\n",
    "                                             y_train))\n",
    "\n",
    "w_array = np.ones(y_train.shape[0], dtype = 'float')\n",
    "for i, val in enumerate(y_train):\n",
    "    w_array[i] = class_weights[val-1]\n",
    "\n",
    "w_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(alpha = 0.05, fit_prior=False)\n",
    "nb.fit(x_train_vector, y_train)\n",
    "pred = nb.predict(x_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.81       231\n",
      "           1       0.98      0.94      0.96      1260\n",
      "\n",
      "    accuracy                           0.93      1491\n",
      "   macro avg       0.86      0.93      0.89      1491\n",
      "weighted avg       0.94      0.93      0.94      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB_result = evaluate(x_test_vector,y_test,nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.50      0.62       231\n",
      "           1       0.91      0.98      0.95      1260\n",
      "\n",
      "    accuracy                           0.91      1491\n",
      "   macro avg       0.87      0.74      0.78      1491\n",
      "weighted avg       0.90      0.91      0.90      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 7,\n",
    "                           weights = 'uniform',\n",
    "                           algorithm ='auto')\n",
    "knn.fit(x_train_vector, y_train)\n",
    "\n",
    "knn_result = evaluate(x_test_vector,y_test,knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.46      0.58       231\n",
      "           1       0.91      0.98      0.94      1260\n",
      "\n",
      "    accuracy                           0.90      1491\n",
      "   macro avg       0.85      0.72      0.76      1491\n",
      "weighted avg       0.89      0.90      0.89      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 7,\n",
    "                           weights = 'uniform',\n",
    "                           algorithm ='auto')\n",
    "knn.fit(x_train_vector2, y_train)\n",
    "\n",
    "knn_result = evaluate(x_test_vector2,y_test,knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from lightgbm import LGBMClassifier, plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tf1\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.67      0.77       231\n",
      "           1       0.94      0.99      0.96      1260\n",
      "\n",
      "    accuracy                           0.94      1491\n",
      "   macro avg       0.92      0.83      0.86      1491\n",
      "weighted avg       0.94      0.94      0.93      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbmclf = LGBMClassifier(leaning_rate = 0.1,\n",
    "                         num_iteration = 1000,\n",
    "                        boosting = 'goss',\n",
    "                         objective = 'binary',\n",
    "                        max_depth = 16,\n",
    "                        scale_pos_weight = 10,\n",
    "                        randomseed = 123)\n",
    "lgbmclf.fit(x_train_vector, y_train)\n",
    "lgbm_result = evaluate(x_test_vector,y_test,lgbmclf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tf1\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78       231\n",
      "           1       0.95      0.98      0.96      1260\n",
      "\n",
      "    accuracy                           0.94      1491\n",
      "   macro avg       0.91      0.84      0.87      1491\n",
      "weighted avg       0.94      0.94      0.94      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgbmclf = LGBMClassifier(leaning_rate = 0.1,\n",
    "                         num_iteration = 1000,\n",
    "                        boosting = 'goss',\n",
    "                         objective = 'binary',\n",
    "                        max_depth = 16,\n",
    "                        scale_pos_weight = 10,\n",
    "                        randomseed = 123)\n",
    "lgbmclf.fit(x_train_vector2, y_train)\n",
    "lgbm_result2 = evaluate(x_test_vector2,y_test,lgbmclf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.52      0.65       231\n",
      "           1       0.92      0.99      0.95      1260\n",
      "\n",
      "    accuracy                           0.91      1491\n",
      "   macro avg       0.90      0.75      0.80      1491\n",
      "weighted avg       0.91      0.91      0.90      1491\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(leaning_rate = 0.1,\n",
    "                         num_iteration = 1000,\n",
    "                        boosting = 'gbtree',\n",
    "                        max_depth = 32,\n",
    "                        scale_pos_weight = 10,\n",
    "                   randomseed = 123)\n",
    "xgb.fit(x_train_vector, y_train, sample_weight = w_array)\n",
    "evaluate(x_test_vector,y_test,xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.73      0.81       231\n",
      "           1       0.95      0.99      0.97      1260\n",
      "\n",
      "    accuracy                           0.95      1491\n",
      "   macro avg       0.93      0.86      0.89      1491\n",
      "weighted avg       0.95      0.95      0.95      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier(loss = 'hinge')\n",
    "sgd.fit(x_train_vector, y_train)\n",
    "sgd_result = evaluate(x_test_vector, y_test, sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.71      0.80       231\n",
      "           1       0.95      0.99      0.97      1260\n",
      "\n",
      "    accuracy                           0.95      1491\n",
      "   macro avg       0.93      0.85      0.88      1491\n",
      "weighted avg       0.94      0.95      0.94      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd2 = SGDClassifier(loss='hinge')\n",
    "sgd2.fit(x_train_vector2, y_train)\n",
    "sgd_result2 =evaluate(x_test_vector2, y_test, sgd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.81       231\n",
      "           1       0.95      0.99      0.97      1260\n",
      "\n",
      "    accuracy                           0.95      1491\n",
      "   macro avg       0.93      0.86      0.89      1491\n",
      "weighted avg       0.95      0.95      0.95      1491\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel = 'sigmoid', C= 1.0, random_state=0)\n",
    "svc.fit(x_train_vector, y_train)\n",
    "evaluate(x_test_vector, y_test, svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.1}"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    gammas = [0.001, 0.01, 0.1, 1]\n",
    "    param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='rbf'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "svc_param_selection(x_train_vector, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'degree': 0}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def svc_param_selection(X, y, nfolds):\n",
    "    Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "    degrees = [0, 1, 2, 3, 4, 5, 6]\n",
    "    param_grid = {'C': Cs, 'degree' : degrees}\n",
    "    grid_search = GridSearchCV(svm.SVC(kernel='linear'), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "\n",
    "svc_param_selection(x_train_vector, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82       231\n",
      "           1       0.96      0.98      0.97      1260\n",
      "\n",
      "    accuracy                           0.95      1491\n",
      "   macro avg       0.93      0.87      0.89      1491\n",
      "weighted avg       0.95      0.95      0.95      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_linear = SVC(kernel = 'linear', C= 1, degree = 0, random_state=0)\n",
    "svc_linear.fit(x_train_vector, y_train)\n",
    "svc_linear_result= evaluate(x_test_vector, y_test, svc_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.83       231\n",
      "           1       0.96      0.98      0.97      1260\n",
      "\n",
      "    accuracy                           0.95      1491\n",
      "   macro avg       0.93      0.88      0.90      1491\n",
      "weighted avg       0.95      0.95      0.95      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#svc best\n",
    "\n",
    "svc = SVC(kernel = 'rbf', C= 10.0, gamma = 0.1, random_state=0)\n",
    "svc.fit(x_train_vector, y_train)\n",
    "svc_result= evaluate(x_test_vector, y_test, svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.83       231\n",
      "           1       0.96      0.98      0.97      1260\n",
      "\n",
      "    accuracy                           0.95      1491\n",
      "   macro avg       0.93      0.88      0.90      1491\n",
      "weighted avg       0.95      0.95      0.95      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#svc best\n",
    "\n",
    "svc2 = SVC(kernel = 'rbf', C= 10.0, gamma = 0.1, random_state=0)\n",
    "svc2.fit(x_train_vector2, y_train)\n",
    "svc_result2= evaluate(x_test_vector2, y_test, svc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lgbm_result, #0.87\n",
    "sgd_result, #0.89\n",
    "svc_result2, #0.90\n",
    "NB_result #0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_best_result2, #0.89\n",
    "CNN_result #0.89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM_best_result2 = np.squeeze(LSTM_best_result2).astype(int)\n",
    "CNN_result = np.squeeze(CNN_result).astype(int)\n",
    "LSTM_best_result2 = np.squeeze(LSTM_best_result2).astype(int)\n",
    "elmo_rsult = np.squeeze(elmo_result).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 1, 0, ..., 1, 1, 1], dtype=int64),\n",
       " array([1, 1, 1, ..., 1, 1, 1], dtype=int64),\n",
       " array([1, 1, 1, ..., 1, 1, 1], dtype=int64),\n",
       " array([1, 1, 0, ..., 1, 1, 1], dtype=int64),\n",
       " array([1, 1, 1, ..., 1, 1, 1]),\n",
       " array([1, 1, 1, ..., 1, 1, 1])]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lgbm_result, sgd_result, svc_result2, NB_result, LSTM_best_result2, CNN_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = lgbm_result + sgd_result + svc_result2 + NB_result + LSTM_best_result2 + CNN_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.86       231\n",
      "           1       0.97      0.98      0.98      1260\n",
      "\n",
      "    accuracy                           0.96      1491\n",
      "   macro avg       0.94      0.90      0.92      1491\n",
      "weighted avg       0.96      0.96      0.96      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_result = np.round(temp/6).astype(int)\n",
    "\n",
    "print(classification_report(y_test, ensemble_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.84      0.87       231\n",
      "           1       0.97      0.98      0.98      1260\n",
      "\n",
      "    accuracy                           0.96      1491\n",
      "   macro avg       0.93      0.91      0.92      1491\n",
      "weighted avg       0.96      0.96      0.96      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = [lgbm_result, sgd_result, svc_result2, NB_result, LSTM_best_result2, CNN_result, elmo_result]\n",
    "temp = sgd_result + svc_result2 + NB_result + LSTM_best_result2 + CNN_result + elmo_rsult\n",
    "ensemble_result2 = np.round(temp/6).astype(int)\n",
    "print(classification_report(y_test, ensemble_result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.85       231\n",
      "           1       0.96      0.99      0.97      1260\n",
      "\n",
      "    accuracy                           0.96      1491\n",
      "   macro avg       0.94      0.89      0.91      1491\n",
      "weighted avg       0.95      0.96      0.95      1491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp =  LSTM_best_result2 + CNN_result + elmo_rsult\n",
    "ensemble_result2 = np.round(temp/3).astype(int)\n",
    "print(classification_report(y_test, ensemble_result2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vo_clf = VotingClassifier(estimators =[('SGD', sgd2),\n",
    "                                       ('SVC', svc2),\n",
    "                                       ('NB',nb),\n",
    "                                       ('LGBM',lgbmclf),\n",
    "                                      ('XGB',xgb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tf1\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83       231\n",
      "           1       0.96      0.99      0.97      1260\n",
      "\n",
      "    accuracy                           0.95      1491\n",
      "   macro avg       0.94      0.87      0.90      1491\n",
      "weighted avg       0.95      0.95      0.95      1491\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vo_clf.fit(x_train_vector, y_train)\n",
    "evaluate(x_test_vector, y_test, vo_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tf1\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.82       231\n",
      "           1       0.96      0.99      0.97      1260\n",
      "\n",
      "    accuracy                           0.95      1491\n",
      "   macro avg       0.93      0.87      0.90      1491\n",
      "weighted avg       0.95      0.95      0.95      1491\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vo_clf.fit(x_train_vector2, y_train)\n",
    "evaluate(x_test_vector2, y_test, vo_clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RS",
   "language": "python",
   "name": "rs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
